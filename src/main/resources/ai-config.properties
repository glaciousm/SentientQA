# AI model configuration
# These settings control the behavior of AI models in Sentinel

# Base directory for model storage
# Models will be automatically downloaded to this location if not present
# Changed to use native Linux filesystem path instead of Windows mounted path to avoid WSL boundary issues
ai.models.base-dir=/home/mmamouze/models

# Language Model Configuration
# Available options: gpt2-medium, gpt-neo-1.3B, bloom-560m
ai.model.language.name=gpt2-medium
# Temporarily disable quantization until model loading is stable
ai.model.language.quantize=false
ai.model.language.quantization-level=FP16
# Available quantization levels: FP16, INT8
# FP16 offers 2x memory reduction with minimal quality loss
# INT8 offers 4x memory reduction with some quality loss
# Format to use for model files (pytorch_model.bin, model.safetensors, etc)
ai.model.format=pytorch_model.bin

# Embeddings Model Configuration
# Available options: all-MiniLM-L6-v2, sbert-mini
ai.model.embeddings.name=all-MiniLM-L6-v2

# System Resource Configurations
# Adjust these based on your hardware capabilities
ai.system.memory-limit-mb=4096
ai.system.use-gpu=false
ai.system.gpu-memory-limit-mb=2048
ai.system.fallback-to-rule-based=true
ai.system.max-load-retries=3
ai.system.load-timeout-ms=120000
ai.system.operation-timeout-ms=60000

# Feature toggles
# Disable resource-intensive features on limited hardware
ai.features.test-generation.enabled=true
ai.features.self-healing.enabled=true
ai.features.code-analysis.enabled=true

# Performance tuning
ai.performance.batch-size=4
ai.performance.cache-embeddings=true
ai.performance.cache-dir=/home/mmamouze/cache

# Model download URLs
# Used when models need to be fetched automatically
model.url.gpt2-medium=https://huggingface.co/gpt2-medium
model.url.all-MiniLM-L6-v2=https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2